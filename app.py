import streamlit as st
import openai
import os
import io
from pydub import AudioSegment
from dotenv import load_dotenv

# --- 1. ì„¤ì • ë° API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
# OPENAI_API_KEYëŠ” Codespaces Secretì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
load_dotenv()
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if OPENAI_API_KEY:
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        st.session_state.client = client
    except Exception as e:
        st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        st.stop()
else:
    st.error("ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GitHub Secretsë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    st.stop()

# --- 2. LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ---

TONE_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ìµœê³ ì˜ ìŠ¤í”¼ì¹˜ ì½”ì¹˜ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì—ê²Œ {purpose}ì— ìµœì í™”ëœ ë°œí™” ë° í˜•ì‹ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]
1. ëª©í‘œ ì²­ì¤‘/ìƒí™©: {purpose}
2. ë°œí™” ìŠ¤í¬ë¦½íŠ¸: "{script}"
3. ì¸¡ì •ëœ ë°œí™” ì†ë„: ë¶„ë‹¹ {wpm} ë‹¨ì–´

[ìš”êµ¬ì‚¬í•­]
1. [ë°œí™” ì†ë„] {purpose}ì— ì í•©í•œ í‘œì¤€ WPMì„ ì œì‹œí•˜ê³ , í˜„ì¬ {wpm}ì´ ì ì ˆí•œì§€ êµ¬ì²´ì ìœ¼ë¡œ ì§„ë‹¨í•˜ê³  ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤.
2. [í†¤ì•¤ë§¤ë„ˆ ë° ì–´íœ˜] ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ {purpose}ì— ë¶€ì í•©í•œ êµ¬ì–´ì²´, ëª¨í˜¸í•œ í‘œí˜„, ë°˜ë³µë˜ê±°ë‚˜ ë¹„ì „ë¬¸ì ì¸ ì–´íœ˜ 5ê°œ ì´ìƒì„ ì§€ì í•˜ê³ , ì´ë¥¼ ëŒ€ì²´í•  ì „ë¬¸ì ì¸ ì–´íœ˜ë‚˜ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ì¶”ì²œí•˜ì‹­ì‹œì˜¤.

ì¶œë ¥ì€ ë°˜ë“œì‹œ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë©°, ê° ì„¹ì…˜ì— ëª…í™•í•œ ì†Œì œëª©ì„ ë¶™ì—¬ì£¼ì‹­ì‹œì˜¤.
"""

LOGIC_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ë…¼ë¦¬ ì»¨ì„¤íŒ… ì „ë¬¸ê°€ì´ë©°, ì²­ì¤‘ì˜ ì§ˆë¬¸ì„ ì˜ˆì¸¡í•˜ëŠ” í›ˆë ¨ëœ ì „ëµê°€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìŠ¤í¬ë¦½íŠ¸ì˜ ë…¼ë¦¬ì  ê²°í•¨ì„ ì°¾ì•„ë‚´ê³ , ì§ˆì˜ì‘ë‹µì„ ì™„ë²½í•˜ê²Œ ëŒ€ë¹„ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]
1. ëª©í‘œ ì²­ì¤‘/ìƒí™©: {purpose}
2. ë°œí™” ìŠ¤í¬ë¦½íŠ¸: "{script}"

[ìš”êµ¬ì‚¬í•­]
1. [ë…¼ë¦¬ ê²°í•¨ ì§„ë‹¨] ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì„ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì²­ì¤‘ì´ ì˜ë¬¸ì„ ê°€ì§ˆ ë§Œí•œ ë…¼ë¦¬ì  ë¹„ì•½, ê·¼ê±° ë¶€ì¡±, ì£¼ì¥ì˜ ëª¨í˜¸ì„± ë“± í•µì‹¬ ì•½ì  3ê°€ì§€ë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤. ê° ì•½ì ì€ ìŠ¤í¬ë¦½íŠ¸ ë‚´ í•´ë‹¹ ë¶€ë¶„ì„ ì¸ìš©í•˜ì—¬ ëª…í™•íˆ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
2. [ì˜ˆìƒ ê¼¬ë¦¬ ì§ˆë¬¸] ì§„ë‹¨ëœ 3ê°€ì§€ ë…¼ë¦¬ì  ì•½ì  ê°ê°ì„ íŒŒê³ ë“œëŠ”, {purpose}ì— ì í•©í•œ ë‚ ì¹´ë¡œìš´ ê¼¬ë¦¬ ì§ˆë¬¸(Follow-up Questions) 3ê°œë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤. (ì´ 9ê°œì˜ ì§ˆë¬¸)
3. [ê°œì„  ë°©ì•ˆ] ë…¼ë¦¬ ê²°í•¨ì„ í•´ì†Œí•˜ê¸° ìœ„í•´ ìŠ¤í¬ë¦½íŠ¸ì— ì¶”ê°€í•´ì•¼ í•  êµ¬ì²´ì ì¸ ë°ì´í„° ìœ í˜•ì´ë‚˜ ì„¤ëª… ìš”ì†Œë¥¼ ì œì‹œí•˜ì‹­ì‹œì˜¤.

ì¶œë ¥ì€ ë°˜ë“œì‹œ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë©°, ê° ì„¹ì…˜ì— ëª…í™•í•œ ì†Œì œëª©ì„ ë¶™ì—¬ì£¼ì‹­ì‹œì˜¤.
"""

# --- 4. STT ë° WPM ê³„ì‚° í•¨ìˆ˜ ---

def process_audio(audio_bytes, filename):
    """Whisper STT ë³€í™˜ ë° WPM/ê¸¸ì´ ê³„ì‚° í†µí•© í•¨ìˆ˜"""
    
    # ì„ì‹œ íŒŒì¼ ê²½ë¡œ
    temp_path = f"/tmp/{filename}"
    with open(temp_path, "wb") as f:
        f.write(audio_bytes)
    
    try:
        # Whisper API í˜¸ì¶œ
        with open(temp_path, "rb") as audio_file:
            transcript_response = st.session_state.client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file,
                response_format="text"
            )
        transcript = transcript_response
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • ë° WPM ê³„ì‚°
        audio = AudioSegment.from_file(temp_path)
        total_time_minutes = len(audio) / 1000 / 60
        word_count = len(transcript.split())
        wpm = round(word_count / total_time_minutes) if total_time_minutes > 0 else 0
        
        os.remove(temp_path) # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        
        return transcript, wpm, total_time_minutes, word_count
        
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬/STT ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
        return None, 0, 0, 0

def get_llm_feedback(script, purpose, wpm):
    """LLMì„ í˜¸ì¶œí•˜ì—¬ ë‘ ê°€ì§€ í”¼ë“œë°±ì„ ìƒì„±"""
    try:
        tone_prompt = TONE_PROMPT_TEMPLATE.format(purpose=purpose, script=script, wpm=wpm)
        tone_response = st.session_state.client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": tone_prompt}]
        )
        tone_feedback = tone_response.choices[0].message.content

        logic_prompt = LOGIC_PROMPT_TEMPLATE.format(purpose=purpose, script=script)
        logic_response = st.session_state.client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": logic_prompt}]
        )
        logic_feedback = logic_response.choices[0].message.content

        return tone_feedback, logic_feedback

    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

# --- 5. Streamlit UI ë° ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---

def main():
    st.set_page_config(page_title="Prep Master: AI ìŠ¤í”¼ì¹˜ ì½”ì¹˜", layout="wide")
    st.title("ğŸ¤ Prep Master: AI ìŠ¤í”¼ì¹˜ ì½”ì¹˜ (STT í†µí•© ë²„ì „)")
    st.markdown("### ë…¹ìŒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ëŒ€ë³¸ì„ ì¶”ì¶œí•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.")
    st.markdown("---")

    col1, col2 = st.columns([1, 1.5])

    with col1:
        purpose = st.selectbox(
            "1. ë°œí‘œ/ë©´ì ‘ ëª©ì ì„ ì„ íƒí•˜ì„¸ìš”:",
            ["IR í”¼ì¹˜ (íˆ¬ì)", "ì·¨ì—… ë©´ì ‘ (ì „ë¬¸ì§)", "í•™ìˆ  ë°œí‘œ (ë…¼ë¬¸)", "ì¼ë°˜ íŒ€ ë°œí‘œ"]
        )
        uploaded_file = st.file_uploader(
            "2. ì—°ìŠµ ë…¹ìŒ íŒŒì¼ (.mp3, .wav, .m4a)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
            type=["mp3", "wav", "m4a"]
        )

    analyze_button = st.button("ğŸš€ AI ì½”ì¹­ ì‹œì‘!", use_container_width=True)
    st.markdown("---")

    if analyze_button:
        if not uploaded_file:
            st.error("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
            st.stop()
        
        with st.spinner('â³ [1/2ë‹¨ê³„] ì˜¤ë””ì˜¤ ë¶„ì„ ë° ëŒ€ë³¸ ì¶”ì¶œ ì¤‘ (Whisper API í˜¸ì¶œ)...'):
            audio_bytes = uploaded_file.read()
            filename = uploaded_file.name
            
            transcript, wpm, total_time, word_count = process_audio(audio_bytes, filename)
            
            if not transcript:
                st.stop()

        with col2:
             st.text_area("ğŸ” Whisperê°€ ì¶”ì¶œí•œ ëŒ€ë³¸", transcript, height=300, disabled=True)
             
        
        with st.spinner('ğŸ§  [2/2ë‹¨ê³„] AIê°€ ë‚´ìš©ê³¼ ë°œí™”ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            tone_feedback, logic_feedback = get_llm_feedback(transcript, purpose, wpm)
            
        if tone_feedback and logic_feedback:
            st.success("ğŸ‰ ë¶„ì„ ì™„ë£Œ! ì•„ë˜ì—ì„œ í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            tab1, tab2 = st.tabs(["ğŸ—£ï¸ ë°œí™” & í˜•ì‹ í”¼ë“œë°±", "ğŸ§  ë‚´ìš© & ë…¼ë¦¬ í”¼ë“œë°±"])
            
            with tab1:
                st.subheader("ğŸ“Š ë°œí™” ì†ë„ ë¶„ì„")
                
                STANDARD_MIN = 120
                STANDARD_MAX = 160
                
                st.metric(
                    label="ì¸¡ì •ëœ ë°œí™” ì†ë„ (WPM)", 
                    value=f"{wpm}", 
                    delta=f"{total_time:.1f}ë¶„ ë™ì•ˆ {word_count}ë‹¨ì–´ ë°œí™”"
                )
                
                color = 'green'
                if wpm < STANDARD_MIN:
                    status_msg = "ëŠë¦¼"
                    color = 'orange'
                elif wpm > STANDARD_MAX:
                    status_msg = "ë¹ ë¦„"
                    color = 'red'
                else:
                    status_msg = "ì ì •"

                st.markdown(f"**ì†ë„ í‰ê°€:** :bulb: <span style='color:{color}'>{status_msg}</span>", unsafe_allow_html=True)
                st.progress(min(wpm / 200.0, 1.0))
                st.markdown("---")
                
                st.subheader("ğŸ—£ï¸ AI ìŠ¤í”¼ì¹˜ ì½”ì¹˜ í”¼ë“œë°±")
                st.markdown(tone_feedback)
                
            with tab2:
                st.markdown(logic_feedback)

if __name__ == "__main__":
    main()